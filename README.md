# ìœ ì‚¬í•œ ë‹¨ì–´ ì°¾ê¸° ê²Œì„
> ë°ì´í„°ì…‹ì—ì„œ ìœ ì‚¬í•œ ë‹¨ì–´ë¥¼ ì°¾ì•„ `A:B = C:D` ë¥¼ ë§Œì¡±í•˜ëŠ” Dë¥¼ ì°¾ì•„ë³´ëŠ” ê²Œì„ì…ë‹ˆë‹¤.

<br>

## í™œìš©í•œ ë°ì´í„°
> ë°ì´í„° ì¶œì²˜: https://data.seoul.go.kr/dataList/OA-22397/F/1/datasetView.do  
> - ì¬ë‚œ ì´ìŠˆ ìœ í˜•ë³„ ë§ë­‰ì¹˜(corpus)

<br>

## ë°ì´í„° ì „ì²˜ë¦¬
```
# ë°ì´í„° ì „ì²˜ë¦¬
from konlpy.tag import Okt
from tqdm import tqdm


# í•œêµ­ì–´ ë¶ˆìš©ì–´ ì²˜ë¦¬
def load_stopwords(filepath):
    with open(filepath, 'r', encoding='UTF-8-sig') as f:
        stopwords = [line.strip() for line in f]
    return stopwords

ko_stopwords = load_stopwords('ko_stopwords.txt')

okt = Okt()
stopwords_ted =  ["ì€", "ëŠ”", "ì´", "ê°€", "ì„", "ë¥¼", "ê³¼", "ì™€", "ë“¤", "ë„", "í•˜ë‹¤", "ì´ë‹¤", "ê»˜ì„œ", "ì—ì„œ","ì—ê²Œ", "ì˜", "ì´ë¼ê³ ", "ì´ë¼ê³ ",
                  "ìœ¼ë¡œ", "ë¡œ", "ì—ì„œ", "ì—ê²Œì„œ", "ìœ¼ë¡œë¶€í„°", "ë¡œë¶€í„°", "ìœ¼ë¡œì¨", "ë¡œì¨"
                "ë¶€í„°", "ê¹Œì§€", "ì—", "ë‚˜", "ë„ˆ", "ê·¸", "ê±”", "ì–˜"]

preprocessed_text = []

# tqdm í™œìš©
for text in tqdm(game_df['text']):
    tokens = okt.morphs(text, stem=True)
    tokens = [token for token in tokens if token not in ko_stopwords]
    tokens = [token for token in tokens if token not in stopwords_ted]
    preprocessed_text.append(tokens)

preprocessed_text
```

<br>

## ëª¨ë¸ í•™ìŠµ ê²°ê³¼
```
fasttext_model.wv.most_similar('ë°©ì‚¬ëŠ¥')

[('ë°©ì‚¬ì„±', 0.9856238961219788),
 ('ë°©ì‚¬', 0.9842268824577332),
 ('ë°©ì‚¬ì²­', 0.976813793182373),
 ('ëŠ¥', 0.9678596258163452),
 ('ë°©ì‚¬ì„ ', 0.966058075428009),
 ('ìƒë°©ì‚¬', 0.9332483410835266),
 ('ì„¸ìŠ˜', 0.9089751839637756),
 ('íƒì‚¬ì„ ', 0.878200888633728),
 ('ì˜¤ì—¼ìˆ˜', 0.8547028303146362),
 ('ë¼ëˆ', 0.8510088920593262)]

```

## ì‹¤í–‰ ê²°ê³¼
```
6700ì–µ:9300ì–µ = 6700ë§Œ:9300ë§Œ
8300ë§Œ
Cì™€ D ìœ ì‚¬ë„: 0.95
ë‹¹ì‹ ì€ ìœ ì¶”ì˜ ì²œì¬ğŸª„
```
- í•™ìŠµ ì„±ëŠ¥ ê°œì„ ì´ í•„ìš”..
